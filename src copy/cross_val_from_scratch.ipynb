{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for cross validation\n",
    "\n",
    "# Split the data with stratification into cv and test sets\n",
    "cv_data_sc, test_data_sc, cv_labels_sc, test_labels_sc = train_test_split(graphs_sc, labels_sc, test_size=0.15, random_state=42, stratify=labels_sc)\n",
    "cv_data_sc_combined, test_data_sc_combined, cv_labels_sc_combined, test_labels_sc_combined = train_test_split(graphs_sc_combined, labels_sc_combined, test_size=0.15, random_state=42, stratify=labels_sc_combined)\n",
    "\n",
    "print(f'cv_data_sc len: {len(cv_data_sc)}, type: {type(cv_data_sc)}')\n",
    "print(f'test_data_sc len: {len(test_data_sc)}, type: {type(test_data_sc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "\n",
    "# Define the parameter grid\n",
    "\"\"\"\n",
    "param_grid = {\n",
    "    'num_heads': [1, 3, 5],\n",
    "    'hidden_channels': [8, 16],\n",
    "    'out_channels': [8, 16],\n",
    "    'num_epochs': [50, 100],\n",
    "    'learning_rate': [1e-5, 1e-4, 1e-3]\n",
    "}\n",
    "\"\"\"\n",
    "# parameter grid simplified\n",
    "param_grid = {\n",
    "    'num_heads': [1],\n",
    "    'out_channels': [16, 32],\n",
    "    'num_epochs': [30, 50],\n",
    "    'learning_rate': [1e-5, 1e-4]\n",
    "    }\n",
    "\n",
    "def perform_grid_search(graphs, labels, num_splits, param_grid, model, criterion, optimizer, device):\n",
    "    \n",
    "    # Initialize StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store overall metrics\n",
    "    overall_results = []\n",
    "\n",
    "    # Loop over each parameter combination\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        num_heads = params['num_heads']\n",
    "        hidden_channels = params['hidden_channels']\n",
    "        out_channels = params['out_channels']\n",
    "        num_epochs = params['num_epochs']\n",
    "        learning_rate = params['learning_rate']\n",
    "        batch_size = params['batch_size']\n",
    "\n",
    "        fold_train_loss = []\n",
    "        fold_val_loss = []\n",
    "        fold_train_accuracy = []\n",
    "        fold_val_accuracy = []\n",
    "        fold_train_f1 = []\n",
    "        fold_val_f1 = []\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(graphs, labels)):\n",
    "            # Split the dataset into training and validation sets for this fold\n",
    "            train_data = [graphs[i] for i in train_index]\n",
    "            val_data = [graphs[i] for i in val_index]\n",
    "\n",
    "            train_labels = [labels[i] for i in train_index]\n",
    "            val_labels = [labels[i] for i in val_index]\n",
    "\n",
    "            # Create PyTorch datasets and data loaders\n",
    "            train_dataset = GraphDataset(train_data, train_labels)\n",
    "            val_dataset = GraphDataset(val_data, val_labels)\n",
    "\n",
    "            # Create data loaders\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            # Initialize metrics for this fold\n",
    "            train_loss_history = []\n",
    "            val_loss_history = []\n",
    "            train_accuracy_history = []\n",
    "            val_accuracy_history = []\n",
    "            train_f1_history = []\n",
    "            val_f1_history = []\n",
    "\n",
    "            lr = learning_rate  # Initialize learning rate\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss, train_accuracy, train_f1 = train(train_loader, model, criterion, optimizer)\n",
    "                val_loss, val_accuracy, val_f1 = validate(val_loader, model, criterion, device)\n",
    "\n",
    "                # Add metrics to lists\n",
    "                train_loss_history.append(train_loss)\n",
    "                val_loss_history.append(val_loss)\n",
    "                train_accuracy_history.append(train_accuracy)\n",
    "                val_accuracy_history.append(val_accuracy)\n",
    "                train_f1_history.append(train_f1)\n",
    "                val_f1_history.append(val_f1)\n",
    "\n",
    "                #print(f'Params: {params}, Fold [{fold+1}/5], Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}, Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}')\n",
    "                # Code to update the lr\n",
    "                # lr *= learning_rate_decay\n",
    "                # update_lr(optimizer, lr)\n",
    "\n",
    "            # Aggregate metrics for this fold\n",
    "            fold_train_loss.append(train_loss_history)\n",
    "            fold_val_loss.append(val_loss_history)\n",
    "            fold_train_accuracy.append(train_accuracy_history)\n",
    "            fold_val_accuracy.append(val_accuracy_history)\n",
    "            fold_train_f1.append(train_f1_history)\n",
    "            fold_val_f1.append(val_f1_history)\n",
    "\n",
    "        # Calculate average metrics across all folds for this parameter combination\n",
    "        avg_train_loss = np.mean(fold_train_loss, axis=0)\n",
    "        avg_val_loss = np.mean(fold_val_loss, axis=0)\n",
    "        avg_train_accuracy = np.mean(fold_train_accuracy, axis=0)\n",
    "        avg_val_accuracy = np.mean(fold_val_accuracy, axis=0)\n",
    "        avg_train_f1 = np.mean(fold_train_f1, axis=0)\n",
    "        avg_val_f1 = np.mean(fold_val_f1, axis=0)\n",
    "\n",
    "        overall_results.append({\n",
    "            'params': params,\n",
    "            'avg_train_loss': avg_train_loss[-1],\n",
    "            'avg_val_loss': avg_val_loss[-1],\n",
    "            'avg_train_accuracy': avg_train_accuracy[-1],\n",
    "            'avg_val_accuracy': avg_val_accuracy[-1],\n",
    "            'avg_train_f1': avg_train_f1[-1],\n",
    "            'avg_val_f1': avg_val_f1[-1]\n",
    "        })\n",
    "\n",
    "    best_result = max(overall_results, key=lambda x: x['avg_val_f1'])\n",
    "    return best_result['params'], best_result['avg_val_f1'], best_result['avg_val_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "num_splits = 5\n",
    "best_params_sc_combined, best_val_f1_sc_combined, best_val_accuracy_sc_combined = perform_grid_search(cv_data_sc_combined, cv_labels_sc_combined, num_splits, param_grid, batch_size, model, criterion, optimizer, device)\n",
    "print(f'Best parameters for combined connectivity: {best_params_sc_combined}, Best validation F1: {best_val_f1_sc_combined}, Best validation accuracy: {best_val_accuracy_sc_combined}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
